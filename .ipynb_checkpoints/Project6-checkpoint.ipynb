{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.style.use('whitegrid')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "matplotlib.rcParams.update({'figure.figsize': (10, 6)})\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "matplotlib.rcParams.update({'axes.labelsize': 20})\n",
    "matplotlib.rcParams.update({'xtick.labelsize': 12})\n",
    "matplotlib.rcParams.update({'ytick.labelsize': 12})\n",
    "matplotlib.rcParams.update({'font.family': 'Helvetica, Arial, sans-serif'})\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>clarity</th>\n",
       "      <th>color</th>\n",
       "      <th>cut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>SI2</td>\n",
       "      <td>E</td>\n",
       "      <td>Ideal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>SI1</td>\n",
       "      <td>E</td>\n",
       "      <td>Premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>VS1</td>\n",
       "      <td>E</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.29</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>VS2</td>\n",
       "      <td>I</td>\n",
       "      <td>Premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.31</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>SI2</td>\n",
       "      <td>J</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat     x     y     z  depth  table  price clarity color      cut\n",
       "0   0.23  3.95  3.98  2.43   61.5   55.0    326     SI2     E    Ideal\n",
       "1   0.21  3.89  3.84  2.31   59.8   61.0    326     SI1     E  Premium\n",
       "2   0.23  4.05  4.07  2.31   56.9   65.0    327     VS1     E     Good\n",
       "3   0.29  4.20  4.23  2.63   62.4   58.0    334     VS2     I  Premium\n",
       "4   0.31  4.34  4.35  2.75   63.3   58.0    335     SI2     J     Good"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/diamonds.csv')\n",
    "\n",
    "# Remove index and re-order dataset\n",
    "data.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "data = data[['carat', 'x', 'y', 'z', 'depth', 'table', 'price', \n",
    "             'clarity', 'color',\n",
    "             'cut']]\n",
    "\n",
    "# Define cross product (Maybe, Currently just appending the rows clarity to rows color)\n",
    "# Check if it wants that or cross product and then coded where row has value of cross\n",
    "# data['clarity-color'] = data['clarity'] + \"-\" + data['color']\n",
    "\n",
    "# Define categorical data as ints\n",
    "# for col in ['color', 'clarity', 'cut']:\n",
    "#     data[col] = data[col].astype('category');\n",
    "#     data[col] = data[col].cat.codes\n",
    "\n",
    "# Generate normalized data\n",
    "# normalized_data = data.copy();\n",
    "# for col in ['carat', 'x', 'y', 'z', 'depth', 'table', 'price']:\n",
    "#     normalized_data[col] = normalized_data[col]/normalized_data[col].max()\n",
    "\n",
    "# Get 1-hot encoding of clarity-color\n",
    "# crossed_features = pd.get_dummies(data['clarity-color'], sparse=True);\n",
    "\n",
    "# # Remove clarity-color form other DataFrames\n",
    "# data.drop(['clarity-color'], axis=1, inplace=True)\n",
    "# normalized_data.drop(['clarity-color'], axis=1, inplace=True)\n",
    "\n",
    "# # Remove the price from one data\n",
    "# normalized_no_price = normalized_data.drop(['price'], axis=1)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_data.plot(kind='box', logy=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear dimensionality reduction: Linear PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# [CITE] \"04. Dimension Reduction and Images Notebook\" by Eric Larson\n",
    "# i.e. the number of dimensions\n",
    "test_components_count = 9\n",
    "\n",
    "def linear_pca(n_components, matrix):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    %time pca.fit(matrix)\n",
    "    return pca\n",
    "\n",
    "\n",
    "# [CITE] \"04. Dimension Reduction and Images Notebook\" by Eric Larson\n",
    "\n",
    "def pca_comp_range(p):\n",
    "    return np.arange(0,p.n_components)\n",
    "\n",
    "def explained_var(p):\n",
    "    return p.explained_variance_ratio_\n",
    "\n",
    "def cumulative_explained_var(p):\n",
    "    return np.cumsum(explained_var(p))\n",
    "\n",
    "def find_nearest_x_for_y(x,y,value):\n",
    "    index = np.abs(y-value).argmin()\n",
    "    return x[index]\n",
    "\n",
    "def find_90_percent_dimension_count(p):\n",
    "    return find_nearest_x_for_y(pca_comp_range(p), cumulative_explained_var(p),0.9)\n",
    "\n",
    "def plot_explained_variance(pca):    \n",
    "    fig, g = plt.subplots()\n",
    "    cr = pca_comp_range(pca)\n",
    "    expvar = explained_var(pca)\n",
    "    cumexpvar = cumulative_explained_var(pca)\n",
    "    \n",
    "    g.fill_between(cr, 0, expvar, color='blue', \n",
    "        label='individual explained variance')\n",
    "    g.plot(cr, cumexpvar, color='orange', linestyle='-', marker='', \n",
    "        label='cumulative explained variance')\n",
    "    g.axhline(y=0.9,color='gray',linestyle='--', \n",
    "        label='90% accuracy target')\n",
    "    \n",
    "    g.set(xlabel='Principal components',ylabel='Explained variance ratio',\n",
    "        xlim=(0,pca.n_components),ylim=(0,1),\n",
    "        title='Explained variance of components')\n",
    "    g.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_matrix = np.asarray(normalized_no_price)\n",
    "\n",
    "# test_pca = linear_pca(test_components_count, data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_explained_variance(test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalized_no_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "df_train = deepcopy(data)\n",
    "df_test = deepcopy(data)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "##### KERAS #####\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(df_train['cut'])\n",
    "y_test = pd.get_dummies(df_test['cut'])\n",
    "\n",
    "numeric_headers = ['carat', 'x', 'y', 'z', 'depth', 'table']\n",
    "\n",
    "X_train_num =  df_train[numeric_headers].values\n",
    "X_test_num = df_test[numeric_headers].values\n",
    "\n",
    "encoders = dict() \n",
    "categorical_headers = ['color','clarity','cut']\n",
    "\n",
    "for col in categorical_headers:\n",
    "    df_train[col] = df_train[col].str.strip()\n",
    "    df_test[col] = df_test[col].str.strip()\n",
    "    encoders[col] = LabelEncoder()\n",
    "    df_train[col+'_int'] = encoders[col].fit_transform(df_train[col])\n",
    "    df_test[col+'_int'] = encoders[col].transform(df_test[col])\n",
    "    \n",
    "categorical_headers_ints = [x+'_int' for x in categorical_headers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment key\n",
    "# #   = My comments\n",
    "# ##  = Larson comments\n",
    "# ### = Changed code\n",
    "\n",
    "\n",
    "# Columns to generate 1-hots\n",
    "#  education    X occupation\n",
    "#  country      X occupation\n",
    "#  relationship X marital_status X sex\n",
    "#  race         X sex\n",
    "cross_columns = [['clarity', 'color']]\n",
    "\n",
    "\n",
    "# Define the order and layers of the network????\n",
    "## we need to create separate sequential models for each embedding\n",
    "embed_branches = []\n",
    "X_ints_train = []\n",
    "X_ints_test = []\n",
    "all_inputs = []\n",
    "all_branch_outputs = []\n",
    "\n",
    "\n",
    "# For all sets of columns to be crossed\n",
    "for cols in cross_columns:\n",
    "    # Creates labels for categorical data. And stores the map\n",
    "    #  enc.transform translates categorical data to integer\n",
    "    ## encode crossed columns as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "    \n",
    "    ## create crossed labels\n",
    "    # Create dataframe of the columns cross product as string data\n",
    "    X_crossed_train = df_train[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "    X_crossed_test = df_test[cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "    \n",
    "    # fits the label encoder to the [x_crossed_train, x_crossed_test]\n",
    "    enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "    # transform the string to integer for train data\n",
    "    X_crossed_train = enc.transform(X_crossed_train)\n",
    "    print(enc.inverse_transform(X_crossed_train))\n",
    "    # transform the string to integer for test data\n",
    "    X_crossed_test = enc.transform(X_crossed_test)\n",
    "    \n",
    "    # Add elements of x_crossed_train to list of previous x_crossed_train values\n",
    "    X_ints_train.append( X_crossed_train )\n",
    "    # Same with test data\n",
    "    X_ints_test.append( X_crossed_test )\n",
    "    \n",
    "    print(X_ints_train[-1])\n",
    "    ## get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) ## same as the max(df_train[col])\n",
    "    ## create embedding branch from the number of categories\n",
    "    # Create inputs for each of the crossed columns\n",
    "    inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "    # Adds the Inputs to a list\n",
    "    all_inputs.append(inputs)\n",
    "    # Creates an Embedding with input number of categories and output the sqrt(#categories). \n",
    "    #  input_length is max matrix size of input\n",
    "    # Passes inputs into embedding\n",
    "    \n",
    "    print('Input dim for embedding', N)\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    # Flatten the dimension of the Embedding\n",
    "    x = Flatten()(x)\n",
    "    # Add the Flattened Embedding to the list\n",
    "    all_branch_outputs.append(x)\n",
    "\n",
    "# Merge all of the Flattened branches to create a wide_branch\n",
    "## merge the branches together\n",
    "### wide_branch = concatenate(all_branch_outputs)\n",
    "wide_branch = all_branch_outputs[0]\n",
    "\n",
    "## reset this input branch\n",
    "all_branch_outputs = []\n",
    "## add in the embeddings\n",
    "for col in categorical_headers_ints:\n",
    "    ## encode as ints for the embedding\n",
    "    X_ints_train.append( df_train[col].values ) # append NDarrays to list\n",
    "    X_ints_test.append( df_test[col].values )\n",
    "    \n",
    "    ## get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) ## same as the max(df_train[col])\n",
    "    # Input defines the tensor shape\n",
    "    ## create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "    # Create a list of all the Inputs\n",
    "    all_inputs.append(inputs)\n",
    "    \n",
    "    # Same as above\n",
    "    x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_branch_outputs.append(x)\n",
    "    \n",
    "## also get a dense branch of the numeric features\n",
    "all_inputs.append(Input(shape=(X_train_num.shape[1],),sparse=False, name='numeric_data'))\n",
    "# Create 20 node dense NN with relu activation\n",
    "print(all_inputs[-1])\n",
    "x = Dense(units=5, activation='relu')(all_inputs[-1])\n",
    "all_branch_outputs.append( x )\n",
    "\n",
    "## merge the branches together\n",
    "deep_branch = concatenate(all_branch_outputs)\n",
    "deep_branch = Dense(units=50,activation='relu')(deep_branch)\n",
    "deep_branch = Dense(units=10,activation='relu')(deep_branch)\n",
    "    \n",
    "final_branch = concatenate([wide_branch, deep_branch])\n",
    "final_branch = Dense(units=5,activation='sigmoid')(final_branch)\n",
    "\n",
    "model = Model(inputs=all_inputs, outputs=final_branch)\n",
    "\n",
    "model.compile(optimizer='adagrad',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "print(y_train.head())\n",
    "\n",
    "\n",
    "model.fit(X_ints_train+ [X_train_num],\n",
    "        np.asarray(y_train), epochs=10, batch_size=35, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
