{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plt.style.use('whitegrid')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "matplotlib.rcParams.update({'figure.figsize': (10, 6)})\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "matplotlib.rcParams.update({'axes.labelsize': 20})\n",
    "matplotlib.rcParams.update({'xtick.labelsize': 12})\n",
    "matplotlib.rcParams.update({'ytick.labelsize': 12})\n",
    "matplotlib.rcParams.update({'font.family': 'Helvetica, Arial, sans-serif'})\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.394000e+04</td>\n",
       "      <td>5.394000e+04</td>\n",
       "      <td>5.394000e+04</td>\n",
       "      <td>5.394000e+04</td>\n",
       "      <td>5.394000e+04</td>\n",
       "      <td>5.394000e+04</td>\n",
       "      <td>5.394000e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.149807e-16</td>\n",
       "      <td>2.508108e-16</td>\n",
       "      <td>-2.107654e-17</td>\n",
       "      <td>-2.023348e-16</td>\n",
       "      <td>-4.002434e-15</td>\n",
       "      <td>1.175017e-16</td>\n",
       "      <td>-1.095980e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.261446e+00</td>\n",
       "      <td>-5.109073e+00</td>\n",
       "      <td>-5.020884e+00</td>\n",
       "      <td>-5.014510e+00</td>\n",
       "      <td>-1.308748e+01</td>\n",
       "      <td>-6.470013e+00</td>\n",
       "      <td>-9.040868e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.395154e-01</td>\n",
       "      <td>-9.103164e-01</td>\n",
       "      <td>-8.882717e-01</td>\n",
       "      <td>-8.909378e-01</td>\n",
       "      <td>-5.231005e-01</td>\n",
       "      <td>-6.521325e-01</td>\n",
       "      <td>-7.476738e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.066190e-01</td>\n",
       "      <td>-2.777527e-02</td>\n",
       "      <td>-2.147379e-02</td>\n",
       "      <td>-1.237607e-02</td>\n",
       "      <td>3.531645e-02</td>\n",
       "      <td>-2.046032e-01</td>\n",
       "      <td>-3.839636e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.106635e-01</td>\n",
       "      <td>7.210475e-01</td>\n",
       "      <td>7.052356e-01</td>\n",
       "      <td>7.103118e-01</td>\n",
       "      <td>5.239313e-01</td>\n",
       "      <td>6.904554e-01</td>\n",
       "      <td>3.487834e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.885992e+00</td>\n",
       "      <td>4.465161e+00</td>\n",
       "      <td>4.654922e+01</td>\n",
       "      <td>4.004720e+01</td>\n",
       "      <td>1.204128e+01</td>\n",
       "      <td>1.680151e+01</td>\n",
       "      <td>3.732404e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              carat             x             y             z         depth  \\\n",
       "count  5.394000e+04  5.394000e+04  5.394000e+04  5.394000e+04  5.394000e+04   \n",
       "mean   2.149807e-16  2.508108e-16 -2.107654e-17 -2.023348e-16 -4.002434e-15   \n",
       "std    1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "min   -1.261446e+00 -5.109073e+00 -5.020884e+00 -5.014510e+00 -1.308748e+01   \n",
       "25%   -8.395154e-01 -9.103164e-01 -8.882717e-01 -8.909378e-01 -5.231005e-01   \n",
       "50%   -2.066190e-01 -2.777527e-02 -2.147379e-02 -1.237607e-02  3.531645e-02   \n",
       "75%    5.106635e-01  7.210475e-01  7.052356e-01  7.103118e-01  5.239313e-01   \n",
       "max    8.885992e+00  4.465161e+00  4.654922e+01  4.004720e+01  1.204128e+01   \n",
       "\n",
       "              table         price  \n",
       "count  5.394000e+04  5.394000e+04  \n",
       "mean   1.175017e-16 -1.095980e-16  \n",
       "std    1.000000e+00  1.000000e+00  \n",
       "min   -6.470013e+00 -9.040868e-01  \n",
       "25%   -6.521325e-01 -7.476738e-01  \n",
       "50%   -2.046032e-01 -3.839636e-01  \n",
       "75%    6.904554e-01  3.487834e-01  \n",
       "max    1.680151e+01  3.732404e+00  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/shivam2503/diamonds/data\n",
    "# Pristine copy of dataset (No modification)\n",
    "diamonds = pd.read_csv('data/diamonds.csv')\n",
    "\n",
    "from copy import deepcopy\n",
    "# Features\n",
    "data = deepcopy(diamonds[['carat', 'x', 'y', 'z', 'depth', 'table', 'price',\n",
    "                          'clarity', 'color']])\n",
    "# Lables\n",
    "target = deepcopy(diamonds['cut']).astype('category')\n",
    "\n",
    "# Force all numerical data to zero mean one std\n",
    "for col in ['carat','x','y','z','depth','table','price']:\n",
    "    data[col] = (data[col] - data[col].mean()) / data[col].std()\n",
    "\n",
    "# Define color and clarity as categorical types\n",
    "for col in ['color', 'clarity']:\n",
    "    data[col] = data[col].astype('category');\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split test and train data\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.2)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "##### KERAS #####\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "class WideDeepNetwork():\n",
    "    def __init__(\n",
    "        self, epochs=5, batch_size=35, activation='relu', final_activation='sigmoid', optimizer='adagrad', \n",
    "        loss='mean_squared_error', metrics=['accuracy'], deep_input_size=5, \n",
    "        deep_layer_sizes=[50,10], numeric_features=None, categorical_features=None,\n",
    "        cross_categories=None,\n",
    "    ):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.activation = activation\n",
    "        self.final_activation = final_activation\n",
    "        self.optimizer = optimizer\n",
    "        self.loss = loss\n",
    "        self.metrics = metrics\n",
    "        \n",
    "        self.deep_input_size = deep_input_size\n",
    "        self.deep_layer_sizes = deep_layer_sizes\n",
    "        self.numeric_features = numeric_features\n",
    "        self.categorical_features = categorical_features\n",
    "        self.cross_categories = cross_categories\n",
    "        \n",
    "    def _make_wide_network(self):\n",
    "        ## we need to create separate sequential models for each embedding\n",
    "        embed_branches = []\n",
    "        X_ints_train = []\n",
    "        all_inputs = []\n",
    "        all_branch_outputs = []\n",
    "        \n",
    "        if not all(isinstance(element, list) for element in self.cross_categories):\n",
    "            raise ValueError('cross_categories should be type [[]]')\n",
    "\n",
    "        # For all sets of columns to be crossed\n",
    "        for cols in self.cross_categories:\n",
    "            # Gets number of 1-hot encoded crossed classes given categories and values\n",
    "            N = 1\n",
    "            for col in cols:\n",
    "                N *= len(self.categorical_features[col])\n",
    "            N += 1\n",
    "\n",
    "            ## create embedding branch from the number of categories\n",
    "            # Create inputs for each of the crossed columns\n",
    "            inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "            # Adds the Inputs to a list\n",
    "            all_inputs.append(inputs)\n",
    "            # Creates an Embedding with input number of categories and output the sqrt(#categories). \n",
    "            #  input_length is max matrix size of input\n",
    "            # Passes inputs into embedding\n",
    "            x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "            # Flatten the dimension of the Embedding\n",
    "            x = Flatten()(x)\n",
    "            # Add the Flattened Embedding to the list\n",
    "            all_branch_outputs.append(x)\n",
    "\n",
    "        # Merge branches into one branch\n",
    "        if(len(all_branch_outputs) == 1):\n",
    "            wide_branch = all_branch_outputs[0]\n",
    "        else:\n",
    "            wide_branch = concatinate(all_branch_outputs)\n",
    "            \n",
    "        # Return input layer and wide branch layer\n",
    "        return all_inputs, wide_branch\n",
    "    \n",
    "    def _make_deep_network(self):\n",
    "        if not all(isinstance(element, list) for _, element in self.categorical_features.items()):\n",
    "            raise ValueError('Categorical features must be a dictonary of lists')\n",
    "        \n",
    "        all_inputs = []  \n",
    "        all_branch_outputs = []\n",
    "        \n",
    "        for key, l in self.categorical_features.items():\n",
    "            # Get highest int classification of category feature\n",
    "            N = len(l)\n",
    "\n",
    "            # Input defines the tensor shape\n",
    "            ## create embedding branch from the number of categories\n",
    "            inputs = Input(shape=(1,),dtype='int32', name=key)\n",
    "            # Create a list of all the Inputs\n",
    "            all_inputs.append(inputs)\n",
    "\n",
    "            # Create embeding layer of N with inputs\n",
    "            x = Embedding(input_dim=N, output_dim=int(np.sqrt(N)), input_length=1)(inputs)\n",
    "\n",
    "            x = Flatten()(x)\n",
    "            all_branch_outputs.append(x)\n",
    "\n",
    "        ## also get a dense branch of the numeric features\n",
    "        if len(self.numeric_features) < 1:\n",
    "            raise ValueError('Numeric Features must not be empty')\n",
    "        \n",
    "        # Add numerical input layer\n",
    "        all_inputs.append(Input(shape=(len(self.numeric_features),),sparse=False, name='numeric_data'))\n",
    "\n",
    "        # Gets a dense encoding of all the numerical data\n",
    "        x = Dense(units=self.deep_input_size, activation=self.activation)(all_inputs[-1])\n",
    "        all_branch_outputs.append( x )\n",
    "\n",
    "        # merge the branches together\n",
    "        deep_branch = concatenate(all_branch_outputs)\n",
    "        \n",
    "        # Define the deep layer \n",
    "        for units in self.deep_layer_sizes:\n",
    "            deep_branch = Dense(units=units,activation=self.activation)(deep_branch)\n",
    "            \n",
    "        # Return input layer and deep branch\n",
    "        return all_inputs, deep_branch\n",
    "        \n",
    "    def make_model(self):\n",
    "        # Get all input layers and the network branches\n",
    "        wide_input, wide_branch = self._make_wide_network()\n",
    "        deep_input, deep_branch = self._make_deep_network()\n",
    "        # combine inputs\n",
    "        all_inputs = wide_input + deep_input\n",
    "        \n",
    "        # Define the final output branch to dense 5 nuron output\n",
    "        final_branch = concatenate([wide_branch, deep_branch])\n",
    "        final_branch = Dense(units=5,activation=self.final_activation)(final_branch)\n",
    "        \n",
    "        # Define model with input and outputs\n",
    "        self.model = Model(inputs=all_inputs, outputs=final_branch)\n",
    "        \n",
    "        # Compile to model to allow fiting\n",
    "        self.model.compile(optimizer=self.optimizer,\n",
    "                           loss=self.loss,\n",
    "                           metrics=self.metrics)\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        # Define input format\n",
    "        X_train = []\n",
    "        # Get crossed categorical values\n",
    "        for cols in self.cross_categories:\n",
    "            X_crossed_train = X[cols].apply(lambda x: '_'.join(x), axis=1).astype('category')\n",
    "            X_train.append(X_crossed_train.cat.codes)\n",
    "        # Get single categorical values\n",
    "        for col in list(self.categorical_features.keys()):\n",
    "            X_train.append(X[col].cat.codes)\n",
    "        # Get numerical values\n",
    "        X_train.append(np.asarray(X[self.numeric_features]))\n",
    "        \n",
    "        # Encode the categorical data to 1 hot encoding\n",
    "        y_one_hot = np.asarray(pd.get_dummies(target_train))\n",
    "        \n",
    "        # Model requires X_train in format of [crossed_categorical(ints), Cat_1, Cat_2, Cat_n, [numerical_data]]\n",
    "        self.model.fit(X_train, y_one_hot, \n",
    "                       epochs=self.epochs, batch_size=self.batch_size, \n",
    "                       verbose=print_progress)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Define input format\n",
    "        X_test = []\n",
    "        # Get crossed categorical values\n",
    "        for cols in self.cross_categories:\n",
    "            X_crossed_test = X[cols].apply(lambda x: '_'.join(x), axis=1).astype('category')\n",
    "            X_test.append(X_crossed_test.cat.codes)\n",
    "        # Get single categorical values\n",
    "        for col in list(self.categorical_features.keys()):\n",
    "            X_test.append(X[col].cat.codes)\n",
    "        # Get numerical values\n",
    "        X_test.append(np.asarray(X[self.numeric_features]))\n",
    "        \n",
    "        # Model requires X_test in format of [crossed_categorical(ints), Cat_1, Cat_2, Cat_n, [numerical_data]]\n",
    "        return self.model.predict(X_test)\n",
    "        \n",
    "    # [CITE] http://algoadventures.com/sklearn-from-the-source-code-up-basics/\n",
    "    # ClassifierMixin implementation\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
    "    # end implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "43152/43152 [==============================] - 7s - loss: 0.8046 - categorical_accuracy: 0.6913     \n",
      "Epoch 2/10\n",
      "43152/43152 [==============================] - 6s - loss: 0.7355 - categorical_accuracy: 0.7154     \n",
      "Epoch 3/10\n",
      "43152/43152 [==============================] - 6s - loss: 0.6907 - categorical_accuracy: 0.7316     \n",
      "Epoch 4/10\n",
      "43152/43152 [==============================] - 6s - loss: 0.5964 - categorical_accuracy: 0.7655     \n",
      "Epoch 5/10\n",
      "43152/43152 [==============================] - 6s - loss: 0.5638 - categorical_accuracy: 0.7753     \n",
      "Epoch 6/10\n",
      "43152/43152 [==============================] - 6s - loss: 0.5483 - categorical_accuracy: 0.7833     \n",
      "Epoch 7/10\n",
      "43152/43152 [==============================] - 6s - loss: 0.5383 - categorical_accuracy: 0.7868     \n",
      "Epoch 8/10\n",
      "43152/43152 [==============================] - 6s - loss: 0.5297 - categorical_accuracy: 0.7882     \n",
      "Epoch 9/10\n",
      "43152/43152 [==============================] - 6s - loss: 0.5250 - categorical_accuracy: 0.7904     \n",
      "Epoch 10/10\n",
      "43152/43152 [==============================] - 6s - loss: 0.5192 - categorical_accuracy: 0.7926     \n"
     ]
    }
   ],
   "source": [
    "# Define features\n",
    "numeric_featues = ['carat', 'x', 'y', 'z', 'depth', 'table', 'price']\n",
    "cross_categories = [['clarity','color']]\n",
    "categorical_features = {'clarity': data['clarity'].value_counts().keys().tolist(), \n",
    "                        'color': data['color'].value_counts().keys().tolist()}\n",
    "\n",
    "\n",
    "wdNet = WideDeepNetwork(epochs = 10,\n",
    "                        batch_size = 32,\n",
    "                        optimizer = 'Nadam',\n",
    "                        loss = 'categorical_crossentropy',\n",
    "                        metrics = ['categorical_accuracy'],\n",
    "                        deep_input_size = 25,\n",
    "                        deep_layer_sizes = [35,80,60,25],\n",
    "                        numeric_features = numeric_featues, \n",
    "                        categorical_features = categorical_features, \n",
    "                        cross_categories = cross_categories)\n",
    "\n",
    "wdNet.make_model()\n",
    "wdNet.fit(data_train, target_train, print_progress=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = wdNet.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 267   29    3    9   12]\n",
      " [  34  579   12   11  320]\n",
      " [   3    5 3985  132  159]\n",
      " [   0   12  333 2171  313]\n",
      " [   3  101  556  246 1493]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x134941be0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDgAAALHCAYAAABrBPJ5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAg4AAACg7P0fzW+nce63bncAAAAASURBVDWvBh4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13491b160>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 355,
       "width": 540
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "target_test_one_hot = pd.get_dummies(target_test)\n",
    "cnf = confusion_matrix(\n",
    "    np.asarray(target_test_one_hot).argmax(1),\n",
    "    y_hat.argmax(1)\n",
    ")\n",
    "print(cnf)\n",
    "cnf_norm = cnf.astype('float') / cnf.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cnf_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84563707608594174"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# gets the column of the maximum for each row\n",
    "# then converts it to binary (manual one-hot encoding)\n",
    "y_hat_one_hot = np.zeros(y_hat.shape)\n",
    "y_hat_one_hot[np.arange(y_hat.shape[0]), y_hat.argmax(1)] = 1\n",
    "\n",
    "# ROC Area under Curve score\n",
    "roc_auc_score(\n",
    "    np.asarray(target_test_one_hot),\n",
    "    y_hat_one_hot\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clarity'].value_counts().keys().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
